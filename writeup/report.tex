\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  
\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{hyperref} %For hyperlinks
\usepackage{float} % To place graphs
\usepackage{epstopdf}
\usepackage{mathrsfs}


\title{\LARGE \bf
Recommendation Systems for Amazon.com
}
\author{Nikhil Johri, Zahan Malkani, and Ying Wang
}
\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Modern retailers frequently use recommendation systems to suggest products of 
interest to a collection of consumers. A closely related task is ratings 
prediction, in which the system predicts a numerical rating that a 
user $u$ will assign to a product $p$. In this paper, we build three ratings 
prediction models for a dataset of products and users from Amazon.com. We 
evaluate the strengths and weaknesses of each model, and discuss their 
effectiveness in a recommendation system.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dataset}
\label{sec:dataset}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models}
\label{sec:models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}



%% \begin{thebibliography}{99}
%% \bibitem{tutorial}
%% Smola, A. J., and Scholkopf, B., (1998), ``A Tutorial on Support Vector Regression,'' NeuroCOLT2 Technical Report Series.

%% \bibitem{joac}
%% Joachims, T., (2002), ``Optimizing Search Engines using Clickthrough Data,'' ACM Conference on Knowledge Discovery and Data Mining (KDD).

%% \bibitem{coord1}
x%% Chang, K.W., Cho, J.H, and Chih, J.L., (2008), ``Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines,'' Journal of Machine Learning Research 9 (2008),  pp.1369-1398.

%% \bibitem{coord2}
%% Chang, K.W., Cho, J.H, Chih, J.L., Sathiya Keerthi, S., and Sundararajan, S. (2008), ``A Dual Coordinate Descent Method for Large-scale Linear SVM,'' 25$^{th}$ International Conference on Machine Learning, Helsinki, Finland.


%% \end{thebibliography}

\end{document}
